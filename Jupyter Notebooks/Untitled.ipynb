{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Cost Function* is the mechanism in our neural network that measures the error in an output to the network relative to the expected value. The known input output pairs that we expect the network to produce are called *training data*; a network that optimizes for training data is a *supervised model*. At its most basic representation, it is the a simple difference between the expected and actual result.\n",
    "\n",
    "$C(x) = \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The partial derivative of any single weight value can be determined via the extended chain rule.\n",
    "\n",
    "Questions:\n",
    "    \n",
    "    Since weights in previous layers effect outputs down the line, does that effect need to be considered when analyzing their contribution to the output layer?\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    Since training data is meant to adjust the weight and bias values across all training samples, how do we structure a solution which takes into account changes to these values towards accuracy for multiple training data?\n",
    "    \n",
    "   For the simplest example, one training data point, we can assess the necessary changes by interpretting each weight and bias in the network into a gradient. More specifically, we look at the *cost function*, which measures the difference between the expectec and actual output, and form a vector of partial derivatives corrosponding to each weight (and bias?); this vector is called the *gradient*, and specifies the direction of steepest ascent - by going in the opposite direction the cost/error function is minimized.\n",
    "   \n",
    "   The challenge, as mentioned, is to perform this optimization for multiple training data rather than a single one. This is where *backpropegation* comes into play.\n",
    "    \n",
    "   The *cost function* or *error function* is of greater scope than simply the difference in expected output versus actual output for a single peice of training data; it is in fact the average error across the entire range of training data. This is a necessary expansion since adjusting the weights and biases to fit just a single peice of training data would not ensure that a network can generalize past what it is trained for - it must be trained on a wide variety of data. ;;;(the sum of all the node errors (all of which were made positive through squaring the difference in the error function)). For each \n",
    "   \n",
    "   With this in mind, my current understanding how the backpropegation method might work is that for every peice of training data, a gradient is added into a matrix of column vectors. At this point the cost or error function can be minimized by towards a local minimum by following components of each column vector (partial derivatives of the cost function for each weight/bias in each training instance) which share the same direction of descent. This could be achieved by taking the average of each row in the gradient matrix, and shifting that weight in the general network towards a minimum proportionally to said average.\n",
    "   \n",
    "   So far despite seeing multiple tutorials derive the method of finding the partial derivatives of each weight in the cost function, I have not yet understood how each the appropriate change in weight for is determined if we are working with multiple training data which may have partial derivatives for the same weight, in a different training cycle, which conflict with one another.\n",
    "   \n",
    "   *Backpropegation* refers to the process of finding the magnitude of change for the weights/biases of the previous layer that will make your target layer (starting with the output layer) closer to the desired output. For a single node in your target layer, the gradient of that node's error can be computed with each weight connecting the previous layer's nodes as components. Considering the other input nodes may require movement in different directions, a gradient for each node in your target layer and the wieghts of the node layer previous is computed as previously described. Once this set of gradients is determined, with each node in the target layer corrosponding to a scalar magnitude to shift the weight connections to optimize for that target node, for each weight these scalars are summed, so as to minimize each target node's error as much as possible. \n",
    "   \n",
    "   The result of this single step of backpropegation is that the final layer connection in the network is now optimized to the given training example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After further research, the confusion around backpropegation was largely cleared up. The error function is most simply defined in terms of the output layer, where some function quantifying the difference between an output node's actual output and expected output is employed. From here the backpropegation method can be used for each output node to determine the gradient for each node the layer previous - once this is done for each output node, the set of gradeints for each node in the previous layer is summed to get the net change to that weight.\n",
    "\n",
    "Where the standard challenge comes in is implenenting this method again, from the second to last layer, to the next previous one. The error function relies on node values that can be compared to ideal or target values, which only exist for the final, or output layer. Therefore, another set of gradients cannot be computed without an explicit error function for our hidden layer. Our hidden layer error function takes a node's contribution to each node in the output layer, multiplied by its respective error (the one on the node connecting to the final layer), one for each node in the layer after for which its connected, in this case the output, and sums them together. Each of those terms being summed is divided by all of the weights in the layer for which the error is being computed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropegation is the process of determining how to change the weights and biases in your network to most effectivly fit your training data. This explenation revolves around doing this for a single peice of training data, since doing this for all your training data seperately and then employing one last method to generalize it across the whole training set is how basic backpropegation is actually done.\n",
    "\n",
    "Backpropegation is an iterative process, meaning that the weight and biase changes can be determined for the entire network before those changes are actually made. For this reason, understanding the larger process can be achieved by understanding how to determine these changes for a single layer. This begins with determining error for the output layer, and less plainly, determining error on the hidden layers as well. Since determining this error is the first step for each layer, this explanation will start there.\n",
    "\n",
    "The error of the output of the network is simple enough, and can stand host to different functions. The error term should be a magnitude, that is, a positive real number,,, and each output node can have computed its error. A common choice for this error functions is the difference in expected vs. actual output squared. Once these values are computed, then for each output node, a gradient vector can be determined by comparing the rate of change of each weight to the rate of change of the error - quantifying how each weight connected to that output can be changed to decrease the error; this is the *gradient descent* part of the algorithm. \n",
    "\n",
    "The details to carry through the changing of weights are discussed later, so that now we can answer the question of how we are supposed to repeat this process for the hidden layers if there are no 'expected values' to compare with our hidden node values to quantify our error? We need a formula for determining error on hidden layer nodes, so that the weights connecting to the previous layer can be adjusted the same way as the weights connecting the final hidden layer to the output layer.\n",
    "\n",
    "This 'hidden layer node error' makes use of our already computed error terms. To compute the error for a node in the first hidden layer, we first observe what output nodes it feeds into. This hidden layer node contributes some proportion of error into each output it feeds into, so for each hidden node, the error is the sum consisting of all its weights, each multiplied by the already computed error in the output node that a weight feeds into; importantly, since for every node that our hidden layer node feeds into is also fed into by some number of other hidden nodes from the same layer, each term in the sum is divided by the weights that also feed into the output node, ensuring that the error contributed from  the hidden layer is properly proportioned with all the other hidden nodes feeding into that known, output node error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
